{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### APIs\n",
    "\n",
    "\n",
    "#### Weather API \n",
    "We will use the Weather API from `visualcrossing`. You have to generate you API key that you can later use to access this API. Follow the steps below: \n",
    "\n",
    "1. Signup up at https://www.visualcrossing.com/\n",
    "2. Verify your account\n",
    "3. Sign in and click on `Account` (blue button in the top right corner)\n",
    "4. Under `Details` you should be able to see a `Key`\n",
    "5. Copy the Key in `helper_functions/keys.py`\n",
    "\n",
    "\n",
    "#### HuggingFace Token\n",
    "We will use a model avaialble through a HuggingFace API. For that you need to generate a Token. Follow the steps below: \n",
    "\n",
    "1. Visit [HuggingFace](https://huggingface.co/) and sign up or log in.\n",
    "2. Go to your profile (click your avatar), then \"Settings\" > \"Access Tokens.\"\n",
    "3. Click \"New Token,\" select `Fine-grained` as Token Type role, and check the box `Make calls to the serverless Inference API`\n",
    "4. Copy the Token in `helper_functions/keys.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Update helper_functions.keys.py based on private bin link\n",
    "from helper_functions.keys import WEATHER_KEY, HUGGING_FACE_KEY, OPENAI_KEY\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.agents import AgentExecutor # execute agent\n",
    "from langchain_openai import ChatOpenAI # call openAI as agent llm\n",
    "from langchain.agents import create_tool_calling_agent # set up the agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
